"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_textbook=globalThis.webpackChunkphysical_ai_humanoid_robotics_textbook||[]).push([[246],{5797:(n,e,s)=>{s.r(e),s.d(e,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>t,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"module-2-digital-twin/chapter-2-sensors-fusion","title":"Chapter 2 \u2014 Sensors & Fusion","description":"Learn the essential sensors used in robotics and how to combine their data through sensor fusion for reliable perception.","source":"@site/docs/module-2-digital-twin/chapter-2-sensors-fusion.mdx","sourceDirName":"module-2-digital-twin","slug":"/module-2-digital-twin/chapter-2-sensors-fusion","permalink":"/Physical-AI-Humanoid-Robotics/docs/module-2-digital-twin/chapter-2-sensors-fusion","draft":false,"unlisted":false,"editUrl":"https://github.com/aamnaashraf/Physical-AI-Humanoid-Robotics/edit/main/docs/module-2-digital-twin/chapter-2-sensors-fusion.mdx","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"title":"Chapter 2 \u2014 Sensors & Fusion","description":"Learn the essential sensors used in robotics and how to combine their data through sensor fusion for reliable perception.","keywords":["sensors","sensor fusion","robotics","digital twins","module 2"],"sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 1 \u2014 Simulation Basics","permalink":"/Physical-AI-Humanoid-Robotics/docs/module-2-digital-twin/chapter-1-simulation-basics"},"next":{"title":"Chapter 3 \u2014 Photorealistic Sensors with Unity","permalink":"/Physical-AI-Humanoid-Robotics/docs/module-2-digital-twin/chapter-3-photorealistic-unity"}}');var o=s(4848),r=s(8453);const t={title:"Chapter 2 \u2014 Sensors & Fusion",description:"Learn the essential sensors used in robotics and how to combine their data through sensor fusion for reliable perception.",keywords:["sensors","sensor fusion","robotics","digital twins","module 2"],sidebar_position:2},a="Sensors & Fusion",l={},c=[{value:"Common Robotics Sensors",id:"common-robotics-sensors",level:2},{value:"<strong>1. Cameras</strong>",id:"1-cameras",level:3},{value:"<strong>2. LiDAR</strong>",id:"2-lidar",level:3},{value:"<strong>3. IMU (Inertial Measurement Unit)</strong>",id:"3-imu-inertial-measurement-unit",level:3},{value:"<strong>4. Force/Torque Sensors</strong>",id:"4-forcetorque-sensors",level:3},{value:"Why Sensor Fusion is Important",id:"why-sensor-fusion-is-important",level:2},{value:"Fusion Techniques",id:"fusion-techniques",level:2},{value:"Learning Outcomes for Chapter 2",id:"learning-outcomes-for-chapter-2",level:2}];function d(n){const e={br:"br",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,r.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.header,{children:(0,o.jsx)(e.h1,{id:"sensors--fusion",children:"Sensors & Fusion"})}),"\n",(0,o.jsxs)(e.p,{children:["Robots rely on multiple sensors to perceive their environment. Each sensor has strengths and limitations.",(0,o.jsx)(e.br,{}),"\n",(0,o.jsx)(e.strong,{children:"Sensor fusion"})," combines data from different sensors to create a more accurate and reliable understanding of the world."]}),"\n",(0,o.jsx)(e.hr,{}),"\n",(0,o.jsx)(e.h2,{id:"common-robotics-sensors",children:"Common Robotics Sensors"}),"\n",(0,o.jsx)(e.h3,{id:"1-cameras",children:(0,o.jsx)(e.strong,{children:"1. Cameras"})}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"RGB cameras for visual perception"}),"\n",(0,o.jsx)(e.li,{children:"Depth cameras for 3D perception"}),"\n",(0,o.jsx)(e.li,{children:"Applications: object detection, SLAM, gesture recognition"}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"2-lidar",children:(0,o.jsx)(e.strong,{children:"2. LiDAR"})}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Measures distances using laser pulses"}),"\n",(0,o.jsx)(e.li,{children:"Generates 3D point clouds of the environment"}),"\n",(0,o.jsx)(e.li,{children:"Applications: mapping, navigation, obstacle detection"}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"3-imu-inertial-measurement-unit",children:(0,o.jsx)(e.strong,{children:"3. IMU (Inertial Measurement Unit)"})}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Measures acceleration and angular velocity"}),"\n",(0,o.jsx)(e.li,{children:"Helps estimate robot pose and motion"}),"\n",(0,o.jsx)(e.li,{children:"Applications: stabilization, navigation, odometry"}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"4-forcetorque-sensors",children:(0,o.jsx)(e.strong,{children:"4. Force/Torque Sensors"})}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Measure interaction forces at joints or end-effectors"}),"\n",(0,o.jsx)(e.li,{children:"Applications: manipulation, assembly, safe human-robot interaction"}),"\n"]}),"\n",(0,o.jsx)(e.hr,{}),"\n",(0,o.jsx)(e.h2,{id:"why-sensor-fusion-is-important",children:"Why Sensor Fusion is Important"}),"\n",(0,o.jsx)(e.p,{children:"Single sensors are prone to errors, noise, or occlusions. Sensor fusion improves:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Accuracy of robot localization"}),"\n",(0,o.jsx)(e.li,{children:"Robustness of perception in dynamic environments"}),"\n",(0,o.jsx)(e.li,{children:"Reliability for autonomous navigation and manipulation"}),"\n"]}),"\n",(0,o.jsx)(e.hr,{}),"\n",(0,o.jsx)(e.h2,{id:"fusion-techniques",children:"Fusion Techniques"}),"\n",(0,o.jsx)(e.p,{children:"Some common methods used in robotics:"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Kalman Filter"})," \u2013 combines noisy sensor data for state estimation"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Extended/Unscented Kalman Filters"})," \u2013 handle nonlinear dynamics"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Particle Filters"})," \u2013 probabilistic localization in uncertain environments"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Complementary Filters"})," \u2013 combine fast/slow sensor signals"]}),"\n"]}),"\n",(0,o.jsx)(e.hr,{}),"\n",(0,o.jsx)(e.h2,{id:"learning-outcomes-for-chapter-2",children:"Learning Outcomes for Chapter 2"}),"\n",(0,o.jsx)(e.p,{children:"By the end of this chapter, you should be able to:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Identify core sensors used in robotics"}),"\n",(0,o.jsx)(e.li,{children:"Understand the strengths and limitations of each sensor"}),"\n",(0,o.jsx)(e.li,{children:"Implement basic sensor fusion for robot perception"}),"\n",(0,o.jsx)(e.li,{children:"Apply sensor data to navigation, mapping, and manipulation tasks"}),"\n"]}),"\n",(0,o.jsx)(e.hr,{}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Next Chapter \u2192"})," ",(0,o.jsx)(e.em,{children:"Simulating Robot Movements & Environment Interactions"})]})]})}function h(n={}){const{wrapper:e}={...(0,r.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(d,{...n})}):d(n)}},8453:(n,e,s)=>{s.d(e,{R:()=>t,x:()=>a});var i=s(6540);const o={},r=i.createContext(o);function t(n){const e=i.useContext(r);return i.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function a(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:t(n.components),i.createElement(r.Provider,{value:e},n.children)}}}]);