"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_textbook=globalThis.webpackChunkphysical_ai_humanoid_robotics_textbook||[]).push([[575],{9881:i=>{i.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"link","href":"/Physical-AI-Humanoid-Robotics/docs/intro","label":"Introduction to Physical AI & Humanoid Robotics","docId":"intro","unlisted":false},{"type":"category","label":"Module 1: ROS 2 (Weeks 3-5)","collapsible":true,"collapsed":false,"items":[{"type":"link","href":"/Physical-AI-Humanoid-Robotics/docs/module-1-ros2/","label":"Module 1: ROS 2","docId":"module-1-ros2/index","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics/docs/module-1-ros2/chapter-1-intro-ros2","label":"Chapter 1: Introduction to ROS 2","docId":"module-1-ros2/chapter-1-intro-ros2","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics/docs/module-1-ros2/chapter-2-nodes-topics","label":"Chapter 2: ROS 2 Nodes and Topics","docId":"module-1-ros2/chapter-2-nodes-topics","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics/docs/module-1-ros2/chapter-3-services-actions-parameters","label":"Chapter 3: Services, Actions, and Parameters","docId":"module-1-ros2/chapter-3-services-actions-parameters","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics/docs/module-1-ros2/chapter-4-urdf-robot-modeling","label":"Chapter 4: URDF Robot Modeling","docId":"module-1-ros2/chapter-4-urdf-robot-modeling","unlisted":false}]},{"type":"category","label":"Module 2: Digital Twin (Weeks 6-7)","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/Physical-AI-Humanoid-Robotics/docs/module-2-digital-twin/","label":"Module 2: Digital Twin","docId":"module-2-digital-twin/index","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics/docs/module-2-digital-twin/chapter-1-simulation-basics","label":"Chapter 1 \u2014 Simulation Basics","docId":"module-2-digital-twin/chapter-1-simulation-basics","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics/docs/module-2-digital-twin/chapter-2-sensors-fusion","label":"Chapter 2 \u2014 Sensors & Fusion","docId":"module-2-digital-twin/chapter-2-sensors-fusion","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics/docs/module-2-digital-twin/chapter-3-photorealistic-unity","label":"Chapter 3 \u2014 Photorealistic Sensors with Unity","docId":"module-2-digital-twin/chapter-3-photorealistic-unity","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics/docs/module-2-digital-twin/chapter-4-sim-to-real","label":"From Simulation to Real Robot","docId":"module-2-digital-twin/chapter-4-sim-to-real","unlisted":false}]},{"type":"category","label":"Module 3: NVIDIA Isaac (Weeks 8-10)","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/Physical-AI-Humanoid-Robotics/docs/module-3-isaac/","label":"Module 3: Isaac Sim","docId":"module-3-isaac/index","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics/docs/module-3-isaac/chapter-1-isaac-intro","label":"Isaac Sim \u2014 Introduction & Setup","docId":"module-3-isaac/chapter-1-isaac-intro","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics/docs/module-3-isaac/chapter-2-advanced-vslam","label":"Advanced VSLAM Techniques","docId":"module-3-isaac/chapter-2-advanced-vslam","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics/docs/module-3-isaac/chapter-3-navigation-stacks","label":"Navigation Stacks & Integration","docId":"module-3-isaac/chapter-3-navigation-stacks","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics/docs/module-3-isaac/chapter-4-rl-and-simulations","label":"Reinforcement Learning & Simulation","docId":"module-3-isaac/chapter-4-rl-and-simulations","unlisted":false}]},{"type":"category","label":"Module 4: VLA & Humanoids (Weeks 11-13)","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/Physical-AI-Humanoid-Robotics/docs/module-4-vla-humanoids/","label":"Module 4: VLA & Humanoids","docId":"module-4-vla-humanoids/index","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics/docs/module-4-vla-humanoids/chapter-1-vla-intro","label":"VLA \u2014 Intro & Concepts","docId":"module-4-vla-humanoids/chapter-1-vla-intro","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics/docs/module-4-vla-humanoids/chapter-2-humanoid-kinematics","label":"Humanoid Kinematics Basics","docId":"module-4-vla-humanoids/chapter-2-humanoid-kinematics","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics/docs/module-4-vla-humanoids/chapter-3-manipulation-primitives","label":"Manipulation Primitives","docId":"module-4-vla-humanoids/chapter-3-manipulation-primitives","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics/docs/module-4-vla-humanoids/chapter-4-vla-integration","label":"VLA Integration with Humanoids","docId":"module-4-vla-humanoids/chapter-4-vla-integration","unlisted":false}]},{"type":"category","label":"References","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/Physical-AI-Humanoid-Robotics/docs/references/glossary","label":"Robotics Glossary","docId":"references/glossary","unlisted":false}]}]},"docs":{"intro":{"id":"intro","title":"Introduction to Physical AI & Humanoid Robotics","description":"A streamlined introduction to Physical AI for the Hackathon Edition. Learn the essential skills needed to build intelligent robotics systems that perceive, plan, and act in the physical world.","sidebar":"tutorialSidebar"},"module-1-ros2/chapter-1-intro-ros2":{"id":"module-1-ros2/chapter-1-intro-ros2","title":"Chapter 1: Introduction to ROS 2","description":"Understand the distributed architecture of ROS 2, explore nodes, topics, services, and the computational graph model for robotic systems","sidebar":"tutorialSidebar"},"module-1-ros2/chapter-2-nodes-topics":{"id":"module-1-ros2/chapter-2-nodes-topics","title":"Chapter 2: ROS 2 Nodes and Topics","description":"Master rclpy programming by building publishers, subscribers, and understanding Quality of Service for reliable robot communication","sidebar":"tutorialSidebar"},"module-1-ros2/chapter-3-services-actions-parameters":{"id":"module-1-ros2/chapter-3-services-actions-parameters","title":"Chapter 3: Services, Actions, and Parameters","description":"Master request-response services, long-running actions, and runtime parameters to build sophisticated robotic behaviors","sidebar":"tutorialSidebar"},"module-1-ros2/chapter-4-urdf-robot-modeling":{"id":"module-1-ros2/chapter-4-urdf-robot-modeling","title":"Chapter 4: URDF Robot Modeling","description":"Learn to define robot structure using URDF with links, joints, visual geometry, and kinematic chains for simulation and control","sidebar":"tutorialSidebar"},"module-1-ros2/chapter-5-launch-files-packages":{"id":"module-1-ros2/chapter-5-launch-files-packages","title":"Chapter 5: Launch Files and Package Management","description":"Master ROS 2 package structure, Python launch files, and colcon build system to deploy multi-node robotic applications"},"module-1-ros2/index":{"id":"module-1-ros2/index","title":"Module 1: The Robotic Nervous System (ROS 2)","description":"Master ROS 2 architecture, communication patterns, and robot modeling to build distributed robotic systems","sidebar":"tutorialSidebar"},"module-2-digital-twin/chapter-1-simulation-basics":{"id":"module-2-digital-twin/chapter-1-simulation-basics","title":"Chapter 1 \u2014 Simulation Basics","description":"Learn the core concepts of robotics simulation and why simulation is essential for modern Physical AI workflows.","sidebar":"tutorialSidebar"},"module-2-digital-twin/chapter-2-sensors-fusion":{"id":"module-2-digital-twin/chapter-2-sensors-fusion","title":"Chapter 2 \u2014 Sensors & Fusion","description":"Learn the essential sensors used in robotics and how to combine their data through sensor fusion for reliable perception.","sidebar":"tutorialSidebar"},"module-2-digital-twin/chapter-3-photorealistic-unity":{"id":"module-2-digital-twin/chapter-3-photorealistic-unity","title":"Chapter 3 \u2014 Photorealistic Sensors with Unity","description":"Learn how to simulate realistic sensors using Unity to create high-fidelity Digital Twins for robotics.","sidebar":"tutorialSidebar"},"module-2-digital-twin/chapter-4-sim-to-real":{"id":"module-2-digital-twin/chapter-4-sim-to-real","title":"From Simulation to Real Robot","description":"Simulation provides a safe environment to test algorithms, but the ultimate goal is real-world deployment. This chapter focuses on bridging the gap between virtual environments and actual robotic hardware.","sidebar":"tutorialSidebar"},"module-2-digital-twin/index":{"id":"module-2-digital-twin/index","title":"Module 2: Digital Twins - Simulation & Sensors","description":"Build digital twins for robotic systems using Gazebo and Unity to simulate sensors, physics, and environments","sidebar":"tutorialSidebar"},"module-3-isaac/chapter-1-isaac-intro":{"id":"module-3-isaac/chapter-1-isaac-intro","title":"Isaac Sim \u2014 Introduction & Setup","description":"NVIDIA Isaac Sim is a GPU-accelerated robotics simulator designed for developing, testing, and deploying autonomous robots in high-fidelity 3D environments. It provides realistic physics, photorealistic rendering, and seamless integration with ROS 2.","sidebar":"tutorialSidebar"},"module-3-isaac/chapter-2-advanced-vslam":{"id":"module-3-isaac/chapter-2-advanced-vslam","title":"Advanced VSLAM Techniques","description":"Visual Simultaneous Localization and Mapping (VSLAM) allows robots to build maps of unknown environments while tracking their position in real-time. This chapter focuses on advanced techniques for improving accuracy and robustness.","sidebar":"tutorialSidebar"},"module-3-isaac/chapter-3-navigation-stacks":{"id":"module-3-isaac/chapter-3-navigation-stacks","title":"Navigation Stacks & Integration","description":"Navigation is a critical component for autonomous robots. In this chapter, we focus on deploying and integrating ROS 2 navigation stacks, specifically Nav2, within Isaac Sim and real-world scenarios.","sidebar":"tutorialSidebar"},"module-3-isaac/chapter-4-rl-and-simulations":{"id":"module-3-isaac/chapter-4-rl-and-simulations","title":"Reinforcement Learning & Simulation","description":"Reinforcement Learning (RL) allows robots to learn complex behaviors by interacting with their environment. Isaac Sim provides a safe, high-fidelity environment for training RL policies before deploying them on physical robots.","sidebar":"tutorialSidebar"},"module-3-isaac/index":{"id":"module-3-isaac/index","title":"Module 3: NVIDIA Isaac - Perception & Navigation","description":"Leverage NVIDIA Isaac Sim for GPU-accelerated robotics with VSLAM, Nav2 navigation, and reinforcement learning","sidebar":"tutorialSidebar"},"module-4-vla-humanoids/chapter-1-vla-intro":{"id":"module-4-vla-humanoids/chapter-1-vla-intro","title":"VLA \u2014 Intro & Concepts","description":"Vision-Language-Action (VLA) is a cutting-edge framework for autonomous humanoid robotics. It enables robots to perceive their environment, understand natural language commands, and perform appropriate actions.","sidebar":"tutorialSidebar"},"module-4-vla-humanoids/chapter-2-humanoid-kinematics":{"id":"module-4-vla-humanoids/chapter-2-humanoid-kinematics","title":"Humanoid Kinematics Basics","description":"Humanoid robots rely heavily on kinematics to perform precise movements. Kinematics deals with the geometry of motion without considering the forces causing it.","sidebar":"tutorialSidebar"},"module-4-vla-humanoids/chapter-3-manipulation-primitives":{"id":"module-4-vla-humanoids/chapter-3-manipulation-primitives","title":"Manipulation Primitives","description":"Manipulation primitives are basic building blocks of humanoid robot actions. They allow robots to pick, place, grasp, and interact with objects in the environment.","sidebar":"tutorialSidebar"},"module-4-vla-humanoids/chapter-4-vla-integration":{"id":"module-4-vla-humanoids/chapter-4-vla-integration","title":"VLA Integration with Humanoids","description":"In this chapter, we focus on Vision-Language-Action (VLA) integration, connecting AI language models with humanoid robot perception and control loops. This allows robots to interpret commands and act in the physical world autonomously.","sidebar":"tutorialSidebar"},"module-4-vla-humanoids/index":{"id":"module-4-vla-humanoids/index","title":"Module 4: VLA & Humanoid Robotics","description":"Integrate Vision-Language-Action models with humanoid robots for natural human-robot interaction and manipulation","sidebar":"tutorialSidebar"},"references/glossary":{"id":"references/glossary","title":"Robotics Glossary","description":"Comprehensive glossary of robotics, ROS 2, simulation, and AI terminology used throughout the course","sidebar":"tutorialSidebar"}}}}')}}]);